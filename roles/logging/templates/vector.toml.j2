# Vector configuration for {{ ansible_hostname }}
# Managed by Ansible - Do not edit manually

[api]
enabled = true
address = "127.0.0.1:8686"

# Data directory
data_dir = "/var/lib/vector"

# Sources
[sources.system_logs]
type = "journald"
journal_directory = "/var/log/journal"

{% if logging_container_aware and ansible_facts['services']['docker.service'] is defined %}
[sources.docker_logs]
type = "docker_logs"
docker_host = "unix:///var/run/docker.sock"
{% endif %}

[sources.system_files]
type = "file"
include = [
  "/var/log/syslog",
  "/var/log/auth.log",
  "/var/log/kern.log"
]

# Transforms
[transforms.parse_logs]
type = "remap"
inputs = ["system_logs", "system_files"{% if logging_container_aware %}, "docker_logs"{% endif %}]
source = '''
  .hostname = "{{ ansible_hostname }}"
  .environment = "{{ monitoring_environment | default('production') }}"
  {% if logging_format == "json" %}
  .timestamp = parse_timestamp!(.timestamp, "%Y-%m-%dT%H:%M:%S%.fZ")
  {% endif %}
'''

{% if logging_enable_forwarding and logging_destination %}
# Sinks
{% if 'elasticsearch' in logging_destination or '9200' in logging_destination %}
[sinks.elasticsearch]
type = "elasticsearch"
inputs = ["parse_logs"]
endpoint = "{{ logging_destination }}"
index = "logs-{{ ansible_hostname }}-%Y.%m.%d"

[sinks.elasticsearch.encoding]
codec = "json"
{% elif 'loki' in logging_destination or '3100' in logging_destination %}
[sinks.loki]
type = "loki"
inputs = ["parse_logs"]
endpoint = "{{ logging_destination }}"
labels.hostname = "{{ ansible_hostname }}"
labels.environment = "{{ monitoring_environment | default('production') }}"

[sinks.loki.encoding]
codec = "json"
{% else %}
[sinks.remote_syslog]
type = "syslog"
inputs = ["parse_logs"]
address = "{{ logging_destination }}"
mode = "{{ logging_protocol }}"
{% endif %}
{% endif %}

# Local file sink for debugging
[sinks.local_files]
type = "file"
inputs = ["parse_logs"]
path = "/var/log/vector/processed-%Y-%m-%d.log"

[sinks.local_files.encoding]
codec = "json"
